{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DERIVATIVES PRICING FUNCTIONS\n",
    "* This notebook functions as a bit of an introduction to the underlying theory of options pricing, introducing some concepts like the blackscholes model, implied volatility, brownian motion, geometric brownian motion, (vanilla and exotic) options, and monte carlo techniques. \n",
    "    * Naturally, the accompanying code which implements the introduced theory follows the theoretical introduction in each section\n",
    "    * Additionally, some analysis is given to the computational benefits of vectorising particular operations in options pricing depending on the underlying assumptions / option- which can yield significantly quicker results with just small changes in the underlying code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS\n",
    "* [Introduction to blackscholes model & assumptions](#bs_baseline)\n",
    "    * [Implied Volatility](#iv)\n",
    "* [Tree pricing methods for vanilla options (American / European)](#tree_pricing)\n",
    "* [Introduction to Monte Carlo & Brownian Motion](#bm)\n",
    "    * [Extension to Geometric Brownian Motion](#gbm)\n",
    "* [Monte Carlo supporting math and theory breakdown](#mc_theory)\n",
    "* [Applications of MC pricing: Exotic Options](#exotic_options)\n",
    "* [Variance Reduction techniques in MC pricing](#vr_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Future Planned Content / Expansion\n",
    "* Add 2nd variance reduction method (control variates) & compare to antithetic sampling + do a combined version\n",
    "* Add a LSTM model for MC pricing American Options\n",
    "\n",
    "* improve the robustness of the examples with a sub-sample of real options data\n",
    "    * Thus, could Add GARCH models for volatility forecasts/estimates in the pricing models to better reflect real situations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: I001\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import brentq\n",
    "from scipy.optimize import newton\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bs_baseline'></a>\n",
    "\n",
    "\n",
    "## BLACKSCHOLES MODEL \n",
    "* functions as a sort of baseline model for appraising options\n",
    "* Can be \"reverse engineered\" to return the implied volatility (volatility implied by quoted/traded options in real life) - (next section)\n",
    "* In some instances, E.G. for european options- the BSM is a closed form solution for pricing European options (but not for American options due to the possibility of early exercise)\n",
    "\n",
    "### RESTRICTIVE ASSUMPTIONS OF BLACKSCHOLES MODEL (BSM):\n",
    "* Only works for European options (exercised at expiration)\n",
    "* No dividends paid out during the option's life, but an optional adjustment for averaged dividend yield is possible\n",
    "    * NOTE: traditional assumption is no dividends whatsoever\n",
    "* No transaction or comissions costs\n",
    "* Returns are log-normally distributed\n",
    "* BSM assumes that volatility is constant (like a photo taken at the time of calculation)\n",
    "    * This is perhaps the most unpractical assumption of the model and explains why you cannot use the BSM for real life options trading; as the assumption that volatility is constant for the life of the option is entirely unfeasible\n",
    "\n",
    "### Parameters:\n",
    "- S0 = stock price\n",
    "- K = Strike\n",
    "- T = time to maturity E.G. (3/12) = 4M \n",
    "- r = risk-free rate (discount rate)\n",
    "- sigma = volatility\n",
    "- q = (default=0) dividend % yield "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def blackscholes(\n",
    "    S0: float, K: float, T, r: float, sigma: float, q: float = 0.0, Type: str = \"call\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Price of a European (call or put) in the Black-Scholes model with optional dividend parameter (default=0)\n",
    "    \"\"\"\n",
    "\n",
    "    d1 = (np.log(S0 / K) + ((r - q) + sigma**2 / 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    if Type == \"call\":\n",
    "        value = S0 * norm.cdf(d1) - np.exp((-r - q) * T) * K * norm.cdf(d2)\n",
    "    else:\n",
    "        value = K * np.exp((-r - q) * T) * norm.cdf(-d2) - S0 * np.exp(\n",
    "            (-r - q) * T\n",
    "        ) * norm.cdf(-d1)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_vollib_vectorized.api import vectorized_black_scholes_merton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetical parameters:\n",
    "S0 = 516.0  # QQQ on 1/15/2025\n",
    "K = 520.0  # at 1300 the 3 month (March monthly 520C is ~$)\n",
    "T = 0.16  # 65 dte = 65/365 or 0.16\n",
    "r = 0.425  # 4% rfr\n",
    "sigma = 0.19  # 19% IV on the 520 March 31 2025 calls\n",
    "q = 0.61  # QQQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.265609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price\n",
       "0  7.265609"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_black_scholes_merton(flag=\"c\", S=S0, K=K, t=T, r=r, sigma=sigma, q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.350699454555155\n"
     ]
    }
   ],
   "source": [
    "QQQ_520C = blackscholes(S0, K, T, r, sigma, q, Type=\"call\")\n",
    "print(QQQ_520C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "blackscholes() missing 1 required positional argument: 'q'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mblackscholes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: blackscholes() missing 1 required positional argument: 'q'"
     ]
    }
   ],
   "source": [
    "blackscholes(S0, K, T, r, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASSING IN AN ARRAY OF STRIKES\n",
    "* instead of a singular value for strike (K) - can visualise the price of the option across an array of different strike values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. of range of strikes\n",
    "np.linspace(8, 17, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pass in this array of strike values into the black scholes function to see prices\n",
    "Ks = np.linspace(8, 17, 10)\n",
    "blackscholes(S0, Ks, T, r, sigma, Type=\"call\", q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot the impact of strike (K) on prices (call)\n",
    "plt.plot(Ks, blackscholes(S0, Ks, T, r, sigma, Type=\"call\", q=0))\n",
    "plt.xlabel(\"$Strike (K)$\")\n",
    "plt.ylabel(\"Option Price\")\n",
    "plt.title(\"Call Option Price Curve Relative to Strikes\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='iv'></a>\n",
    "\n",
    "\n",
    "## IMPLIED VOLATILITY\n",
    "\n",
    "* The *implied volatility* (IV, $\\sigma _{I}$) of an option is that value of $\\sigma $ which equates the BS model price to the observed market price $C_{0}^{obs}$, i.e., it solves\n",
    "<br><br>\n",
    "$$\n",
    "C_{0}^{obs}=BS(S_{0},K,T,r,\\sigma_I).\n",
    "$$\n",
    "<br>\n",
    "* If the BS assumptions were correct, then any option traded on the asset should have the same IV, which should in turn equal historical volatility.\n",
    "\n",
    "* In practice, options with different strikes $K$ and hence *moneyness* $K/S_{0}$ have different IVs: this gives rise to the famous: *volatility smile* or *smirk/skew*.\n",
    "\n",
    "    * Also, options with different times to maturity have different IVs: this yields what is known as the *volatility term structure*.\n",
    "\n",
    "* These phenomena (different moneyness = different IV) and (different times to maturity = different IV) are evidence of a failure of the assumptions of the Black-Scholes model\n",
    "    * As mentioned above, the most important failure of the BSM (and why you cannot use it to trade in practice) that of a constant volatility $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def impvol(S0, K, T, r, C_obs, Type=\"call\"):\n",
    "    \"\"\"\n",
    "    Implied Black-Scholes volatility- With Root Finding Function: Scipy Brentq\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## if != call; can convert to call price via parity\n",
    "    if Type == \"put\":\n",
    "        C_obs = C_obs + S0 - np.exp(-r * T) * K\n",
    "\n",
    "    ## else if type = call (function default behaviour)\n",
    "\n",
    "    # theranchi bounds (lower and upper)\n",
    "    # represent upper and lower bounds which hold uniformly across moneyness and call price\n",
    "    # these bounds are used to reprove uniform bounds on IV at extreme strikes and/or maturities\n",
    "    L = -2 * norm.ppf((S0 - C_obs) / (2.0 * min(S0, np.exp(-r * T) * K))) / np.sqrt(T)\n",
    "    U = -2 * norm.ppf((S0 - C_obs) / (S0 + np.exp(-r * T) * K)) / np.sqrt(T)\n",
    "\n",
    "    # Partial application would be:  f(s)=BS(S0, K, T, r, s)-C_obs.\n",
    "    return brentq(lambda s: blackscholes(S0, K, T, r, s) - C_obs, L, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## dummy data for now (C_obs = call price observed in the market)\n",
    "C_obs = 3\n",
    "\n",
    "# hypothetical parameters:\n",
    "S0 = 11.0\n",
    "K = 10.0\n",
    "T = 3 / 12.0\n",
    "r = 0.02\n",
    "sigma = 0.3\n",
    "N = 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IV = impvol(S0, K, T, r, C_obs)\n",
    "print(f\"Implied Volatility: {impvol(S0, K, T, r, C_obs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to re-running the blackscholes from above with the implied volatility (IV) in place of sigma\n",
    "blackscholes(S0, K, T, r, IV)  # IV replaces sigma\n",
    "\n",
    "# returns the original passed value for C_obs of ~ 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This data is for illustrative purposes, the level of implied volatility is very high as the call option price is very high relative to the \"moneyness\" of the option (K/S); additionally, a high IV pushes up the value of both call and put options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tree_pricing'></a>\n",
    "\n",
    "\n",
    "## TREE OPTION PRICING \n",
    "* Specifications: \n",
    "    * Call / Put\n",
    "    * American / European"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def optiontree_flexible(S0, K, T, r, sigma, N, Type=\"call\", option_spec=\"american\"):\n",
    "    \"\"\"\n",
    "    Calculate (American or European) (call & put) prices based on a N-step binomial tree:\n",
    "    \"\"\"\n",
    "\n",
    "    # define delta_t (Time to maturity / number of steps)\n",
    "    deltaT = T / float(N)\n",
    "\n",
    "    # define the factor by which the (up) movement rises\n",
    "    u = np.exp(sigma * np.sqrt(deltaT))\n",
    "\n",
    "    # define d in such a way the tree is recombinant\n",
    "    d = 1.0 / u\n",
    "\n",
    "    # define probabilities according to the theory of risk neutral valuation\n",
    "    p = (np.exp(r * deltaT) - d) / (u - d)\n",
    "\n",
    "    # probabilities (up) and (down) = piu and pid respectively\n",
    "    piu = np.exp(-r * deltaT) * p\n",
    "    pid = np.exp(-r * deltaT) * (1 - p)\n",
    "\n",
    "    # calculate the stock price tree (stock price at origination * up(down) movement factors relative to position in tree\n",
    "    S = S0 * u ** np.arange(N + 1) * d ** (2 * np.arange(N + 1)[:, np.newaxis])\n",
    "\n",
    "    # keep only the upper triangular part (as only non-negative payoffs contribute to price)\n",
    "    S = np.triu(S)\n",
    "\n",
    "    if Type == \"call\":\n",
    "        # initialise the matrix of zeros to be written over for (when payoff > 0) for the payoff structure\n",
    "        C = np.zeros((N + 1, N + 1))\n",
    "\n",
    "        # calculate the payoff for each node in the tree through to (N) steps: larger of (0, or stock - strike price) for call\n",
    "        C[:, N] = np.maximum(0, S[:, N] - K)\n",
    "\n",
    "        # iterate backwards through tree to multiply payoffs by probability of being in that node\n",
    "        for j in range(N - 1, -1, -1):\n",
    "            C[: j + 1, j] = piu * C[: j + 1, j + 1] + pid * C[1 : j + 2, j + 1]\n",
    "\n",
    "            # if option = American; calculate the value of early exercise\n",
    "            if option_spec == \"american\":\n",
    "                C[: j + 1, j] = np.maximum(K - S[: j + 1, j], C[: j + 1, j])\n",
    "\n",
    "        # return the price of the option at origination (which is the weighted sum of payoffs * probabilities) in the tree\n",
    "        return np.round(C[0, 0], 6)\n",
    "\n",
    "    elif Type == \"put\":\n",
    "        # initialise matrix of zeros (could use C again but for clarity, rename it to P)\n",
    "        P = np.zeros((N + 1, N + 1))\n",
    "\n",
    "        # calculate payoff- for put is: maximum of (0, strike-stock)\n",
    "        P[:, N] = np.maximum(0, K - S[:, N])\n",
    "\n",
    "        # iterate through tree of payoffs and probabilities\n",
    "        for j in range(N - 1, -1, -1):\n",
    "            P[: j + 1, j] = piu * P[: j + 1, j + 1] + pid * P[1 : j + 2, j + 1]\n",
    "\n",
    "            # if option = American; calculate the value of early exercise\n",
    "            if option_spec == \"american\":\n",
    "                P[: j + 1, j] = np.maximum(P[: j + 1, j], K - S[: j + 1, j])\n",
    "\n",
    "        # return price at origination\n",
    "        return np.round(P[0, 0], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hypothetical parameters:\n",
    "S0 = 11.0\n",
    "K = 10.0\n",
    "T = 3 / 12.0\n",
    "r = 0.02\n",
    "sigma = 0.3\n",
    "N = 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optiontree_flexible(S0, K, T, r, sigma, N, Type=\"call\", option_spec=\"european\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optiontree_flexible(S0, K, T, r, sigma, N, Type=\"put\", option_spec=\"european\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optiontree_flexible(S0, K, T, r, sigma, N, Type=\"call\", option_spec=\"american\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optiontree_flexible(S0, K, T, r, sigma, N, Type=\"put\", option_spec=\"american\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bm'></a>\n",
    "\n",
    "# MONTE CARLO PRICING SECTION OUTLINE\n",
    "* Introduce Brownian Motion / Geometric Brownian Motion\n",
    "* Introduce Exotic Options & MC pricing \n",
    "* Introduce Sampling Variance Reduction Techniques\n",
    "* Apply Methodology to Vanilla Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## BRIEF INTRODUCTION TO BROWNIAN MOTION / GEOMETRIC BROWNIAN MOTION\n",
    "* In the Monte Carlo (MC) simulations, we need a way to simulate the underlying asset price path. The payoffs are path dependent, and the payoff function does not change over time, simply the value of the underlying asset price which affects the (expected) payoff, and hence the price of the option\n",
    "\n",
    "\n",
    "### SIMULATING BM OUTLINE\n",
    "* We need to discretize it, spliting the time interval $[0,T]$ into $N$ parts of length $\\delta t=T/N $.\n",
    "* Now we model the asset's return (price path) $R_{i}$ as normal (rather than binomial in a tree pricer).\n",
    "    * thus: $ R_{i}=\\sqrt{\\delta t}\\cdot Z_i,\\quad Z_i\\sim\\mathrm{N}(0, 1) $\n",
    "    * Where Z is a random sample from the normal distribution (or pseudo random from numpy's (np.random.randn)) \n",
    "    \n",
    "    \n",
    "#### BM with drift: \n",
    "* As a slight generalization, a *Brownian motion with drift* is obtained from:\n",
    "$$\n",
    "\\delta X_t \\equiv  X_{i\\delta t}-X_{(i-1)\\delta t} =\\mu\\delta t+\\sigma\\delta W_{t}=\\mu\\delta t+\\sigma\\sqrt{\\delta t} Z_i,\n",
    "$$\n",
    "* where we let the change in one time interval essentialy be equal to a drift term + the volatility term. Also, where we allow $X_0$ to be an arbitrary value. (that is, the starting value is not important)\n",
    "\n",
    "\n",
    "* This implies: $X_t\\equiv X_0+\\mu t +\\sigma W_t,$ so that $\\mathbb{E}[X_t]=X_{0}+\\mu t$, $\\mathrm{Var}[X_t]=\\sigma^{2}t$. Hence the average upwards (or downwards if $\\mu<0$) tendency over a time interval $\\delta t$ is $\\mu \\delta t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmsim(T, N, X0=0, mu=0, sigma=1):\n",
    "    \"\"\"Simulate a Brownian motion path with X0/mu = 0 drift terms\"\"\"\n",
    "\n",
    "    # define our time interval\n",
    "    deltaT = float(T) / N\n",
    "\n",
    "    # create the linearly spaced vector of 0 through T, in increments of N + 1\n",
    "    tvec = np.linspace(0, T, N + 1)\n",
    "\n",
    "    # generate random variable from normal distribution to simulate the \"randomness\" of the process\n",
    "    z = np.random.randn(N + 1)\n",
    "\n",
    "    # define the change in process (X) as the formula written above for BM\n",
    "    dX = mu * deltaT + sigma * np.sqrt(deltaT) * z\n",
    "\n",
    "    # define starting point for the process\n",
    "    dX[0] = 0.0\n",
    "\n",
    "    # sum the total changes made to the process (X) with (drift if != 0 and volatility)\n",
    "    # we can vectorise this because the elements are not time varying and don't require the previous period's values\n",
    "    X = np.cumsum(dX)\n",
    "\n",
    "    # return origination value to apply the cumsum of changes to the starting price/level of the process\n",
    "    X += X0\n",
    "    return tvec, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.G. of brownian motion path (with a set random seed)\n",
    "np.random.seed(0)\n",
    "tvec, W = bmsim(1, 1000)\n",
    "W = pd.Series(W, index=tvec)\n",
    "W.plot()\n",
    "plt.title(\"Simulated Brownian Motion Path\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$W_t$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gbm'></a>\n",
    "\n",
    "### GEOMETRIC BROWNIAN MOTION (GBM)\n",
    "* Ito processes generalise BM with drift by allowing both the drift and volatility to be time-varying.\n",
    "\n",
    "* We can now re-write the above BM expression as: \n",
    "$$\n",
    "\\delta X_t\\equiv X_{i\\delta t}-X_{(i-1)\\delta t}=\\mu_{t_{i-1}} \\delta t + \\sigma_{t_{i-1}} \\delta W_t.\n",
    "$$\n",
    "\n",
    "\n",
    "* We allow $\\mu_{t_i}$ and $\\sigma_{t_i}$ to be stochastic; e.g., they may depend on $X_{i-1}$, as in \n",
    "$$\n",
    "\\delta X_t=\\mu(t_{i-1},X_{i-1}) \\delta t + \\sigma(t_{i-1}, X_{i-1}) \\delta W_t.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####  **An example of an Ito process**: \n",
    "* Take $\\mu(t, S_t)\\equiv \\mu S_t$ and $\\sigma(t, S_t)\\equiv \\sigma S_t$. The resulting process\n",
    "$$\n",
    "dS_t=\\mu S_t dt +\\sigma S_t dW_t\n",
    "$$\n",
    "is known as Geometric Brownian Motion (*GBM*). \n",
    "    * Its Euler approximation is\n",
    "$$\n",
    "\\delta S_t \\equiv S_{i}-S_{i-1}=\\mu S_{i-1} \\delta t + \\sigma S_{i-1}  \\sqrt{\\delta t} Z_i.\n",
    "$$\n",
    "\n",
    "* In this approximation the distribution of $\\delta S_t$ (the stock price) is normal (not log-normal as it should be)\n",
    "* Under mild conditions, the error introduced by discretization will disappear as $\\delta t\\rightarrow 0$. (as the time interval width approaches being continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbmsim(T, N, S0=1, mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Simulate a Geometric Brownian motion path with Mu (drift) = 0 and sigma = 1 by means of Euler Approximation\n",
    "    \"\"\"\n",
    "\n",
    "    deltaT = float(T) / N\n",
    "\n",
    "    # create the linearly spaced vector of 0 through T, in increments of N + 1\n",
    "    tvec = np.linspace(0, T, N + 1)\n",
    "\n",
    "    # initialse random numbers through N + 1 for the shape from the normal distribution\n",
    "    z = np.random.randn(N + 1)\n",
    "\n",
    "    # initialise an array of zeros of the same shape (to be iterated over)\n",
    "    S = np.zeros_like(z)\n",
    "\n",
    "    # define the starting point for the iteration to be (1)\n",
    "    S[0] = S0\n",
    "\n",
    "    # Note: we can no longer vectorize this, because S[:, j] is needed for S[:, j+1]. (time varying element)\n",
    "    for i in range(0, N):\n",
    "        S[i + 1] = S[i] + mu * S[i] * deltaT + sigma * S[i] * np.sqrt(deltaT) * z[i + 1]\n",
    "\n",
    "    return tvec, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tvec, S = gbmsim(1, 1000)\n",
    "S = pd.Series(S, index=tvec)\n",
    "S.plot()\n",
    "plt.title(\"Simulated Geometric Brownian Motion Path\")\n",
    "# x label is time; y label is stock\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$S_t$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mc_theory'></a>\n",
    "\n",
    "# MONTE CARLO PRICING - THEORY INTRODUCTION\n",
    "\n",
    "* The goal in Monte Carlo simulations is to obtain an estimate of (theta) denoted:\n",
    "\n",
    "$$\n",
    "\\theta\\equiv \\mathbb{E}[X],\n",
    "$$\n",
    "\n",
    "\n",
    "for some random variable $X$ with finite expectation. The assumption is that we have a means of sampling from the distribution of $X$, but no closed-form expression for $\\theta$. (As is the case for American options, for instance)\n",
    "* Suppose we have a sample $\\{X_i\\}_{i\\in\\{1,\\ldots,n\\}}$ of *independent* draws for $X$, and let\n",
    "$$\n",
    "\\bar{X}_n=\\frac{1}{n}\\sum_{i=1}^n X_i.\n",
    "$$\n",
    "* The sample average $\\bar{X}_n$ is an *unbiased estimator* of $\\theta$ : $\\mathbb{E}[\\bar{X}_n]=\\theta$.\n",
    "* The *weak law of large numbers* states that\n",
    "$$\n",
    "\\bar{X}_n\\stackrel p \\rightarrow \\theta,\n",
    "$$\n",
    "where the arrow denotes *convergence in probability*; i.e., as the sample size grows, $\\bar X_n$ becomes a better and better estimate of $\\theta$. \n",
    "    * Although, techniques exist to improve the estimate of $\\theta$ (that is, reduce the sampling variance) without having to infinitely grow the sample size. This project will include two such techniques: \n",
    "        * Antithetic sampling \n",
    "        * Control variates \n",
    "        \n",
    "        \n",
    "## MC PROCESS OUTLINE:\n",
    "* Thus, our strategy is to use a computer to draw $n$ (pseudo) random numbers $X_i$ from the distribution of $X$, and then estimate $\\theta$ as the sample mean of the $X_i$.\n",
    "* $n$ is called the number of *replications*.\n",
    "* For finite $n$, the sample average will be an approximation to $\\theta$. \n",
    "* It is usually desirable to have an estimate of the accuracy of this approximation. Such an estimate can be obtained from the *central limit theorem* (CLT), which states that\n",
    "$$\n",
    "\\sqrt{n}(\\bar{X}_n-\\theta)\\stackrel d\\rightarrow N\\left(0,\\sigma^2\\right),\n",
    "$$\n",
    "provided that $\\sigma^2$, the variance of $X$, is finite. The arrow denotes convergence in distribution\n",
    "    * this implies that for large $n$, $\\bar{X}_n$ has approximately a normal distribution.\n",
    "    \n",
    "    \n",
    "    \n",
    "* Of course $\\sigma^2$ is unknown, but we can estimate it in the traditional sense as\n",
    "$$\n",
    "\\hat{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^n \\left(\\bar{X}_n-X_i\\right)^2.\n",
    "$$\n",
    "\n",
    "### CONFIDENCE INTERVALS IN MC SIMULATIONS: \n",
    "* A 95% *confidence interval* (CI) is an interval $[c_l,c_u]$ with\n",
    "$\n",
    "\\mathbb{P}[c_l\\leq \\theta \\leq c_u]=0.95.\n",
    "$\n",
    "* The CLT implies that, in the limit as $n\\rightarrow\\infty$,\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{P}[-1.96 \\sigma\\leq \\sqrt{n}(\\bar{X}_n-\\theta)\\leq 1.96 \\sigma ]&=0.95\\Leftrightarrow\\\\\n",
    "\\mathbb{P}[\\bar{X}_n-1.96 \\frac{\\sigma}{\\sqrt{n}}\\leq \\theta\\leq \\bar{X}_n+1.96 \\frac{\\sigma}{\\sqrt{n}} ]&=0.95.\n",
    "\\end{align*}\n",
    "* Hence $c_l=\\bar{X}_n-1.96 \\frac{\\sigma}{\\sqrt{n}}$ and $c_u=\\bar{X}_n+1.96 \\frac{\\sigma}{\\sqrt{n}}$ is an asymptotically valid CI.\n",
    "* Note that $c_l$ and $c_u$ are random variables; we should interpret this as \"before the experiment is performed, there is a 95% chance that a CI computed according to this formula will contain $\\theta$\". \n",
    "    * The intuition behind confidence levels in MC work slightly differently; hence, after performing the experiment, this statement is not valid anymore. The interval is now fixed, and contains $\\theta$ with probability either 0 or 1.\n",
    "* The unknown parameter $\\sigma$ can be consistently estimated by $\\sqrt{\\hat{\\sigma}^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exotic_options'></a>\n",
    "\n",
    "# APPLICATIONS OF MC PRICING - EXOTIC OPTIONS: \n",
    "## (1): ASIAN OPTIONS \n",
    "\n",
    "* The payoff of Asian options depends on the *average* price of the underlying, $\\bar{S}_T$. Types:\n",
    "  * Average price Asian call with payoff $(\\bar{S}_T-K)^+$;\n",
    "  * Average price Asian put with payoff $(K-\\bar{S}_T)^+$;\n",
    "  * Average strike Asian call with payoff $(S_T-\\bar{S}_T)^+$;\n",
    "  * Average strike Asian put with payoff $(\\bar{S}_T-S_T)^+$.\n",
    "\n",
    "\n",
    "* The type of average is important in the calculation - here we consider the arithmetic average: \n",
    "$$\n",
    "\\qquad\n",
    "\\frac{1}{N}\\sum_{i=1}^N S_{t_i}\n",
    "$$\n",
    "where the $t_i$ are a set of $N$ specified dates.\n",
    "\n",
    "## NOTE: An exact pricing formula exists only for a geometric average asian call, hence we rely upon a MC simulation\n",
    "* With the pricing formula\n",
    "$$\n",
    "C_{t}=e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[ \\left.\n",
    "C_{T}\\right\\vert \\mathcal{F}_{t}\\right] \n",
    "$$\n",
    "\n",
    "\n",
    "* The arithmetic average price call cannot be priced analytically, hence rely upon the MC simulation\n",
    "* The asian call's payoff is: \n",
    "$$\n",
    "C_T=(\\bar{S}_T-K)^+,\\quad\\mbox{where}\\quad \\bar{S}_T=\\frac{1}{N}\\sum_{i=1}^N S_{t_i},\n",
    "$$\n",
    "* The payoff is *path-dependent*, so we need to simulate the entire asset price path, not just $S_T$. (the final price at maturity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asian_mc(S0, K, T, r, sigma, q, N, numsim=10000):\n",
    "    \"\"\"\n",
    "    Monte Carlo price of an arithmetic average Asian call.\n",
    "    S0 = initial stock price\n",
    "    K = strike price\n",
    "    T = time to maturity\n",
    "    r = risk-free rate (discount rate)\n",
    "    sigma = volatility\n",
    "    q = dividend rate\n",
    "    N = number of steps\n",
    "    ## NOTE: (r-q) is the appropriate adjustment to the discount rate (r) by dividend rate (q)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # simulate the log of the stock price\n",
    "    X0 = np.log(S0)\n",
    "\n",
    "    # define our drift term for brownian motion\n",
    "    nu = r - q - 0.5 * sigma**2\n",
    "\n",
    "    # simulate the shape of zeros in the form of numsim\n",
    "    payoffs = np.zeros(numsim)\n",
    "\n",
    "    # iterate through the number of simulations\n",
    "    for i in range(numsim):\n",
    "        _, X = bmsim(\n",
    "            T, N, X0, nu, sigma\n",
    "        )  # just need (X), hence the underscore can be discarded\n",
    "\n",
    "        # simulate the exponential of (X) the stock price path in the brownian motion simulation\n",
    "        S = np.exp(X)\n",
    "\n",
    "        # apply our payoff function: note ignore S0 (originaiton price) in the mean\n",
    "        payoffs[i] = max(S[1:].mean() - K, 0.0)  # We ignore S0 in the mean.\n",
    "\n",
    "    # discount the payoffs\n",
    "    g = np.exp(-r * T) * payoffs\n",
    "\n",
    "    # define the discounted payoffs mean and standard deviation\n",
    "    C = g.mean()\n",
    "    s = g.std()\n",
    "\n",
    "    # define the normal distribution 97.5% percentage point function\n",
    "    zq = norm.ppf(0.975)\n",
    "\n",
    "    # define our confidence interval for lower (cl) and upper(cu) (formula in markdown above)\n",
    "    Cl = C - (zq * s) / np.sqrt(numsim)\n",
    "    Cu = C + (zq * s) / np.sqrt(numsim)\n",
    "\n",
    "    # return C (price of option) + confidence intervals\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define dummy data for testing purposes:\n",
    "S0 = 11\n",
    "K = 10\n",
    "T = 3 / 12.0\n",
    "r = 0.02\n",
    "sigma = 0.3\n",
    "q = 0.01\n",
    "N = 10\n",
    "\n",
    "# ensure random seed for comparability\n",
    "np.random.seed(0)\n",
    "\n",
    "C0, Cl, Cu = asian_mc(S0, K, T, r, sigma, q, N)\n",
    "C0, Cl, Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit asian_mc(S0, K, T, r, sigma, q, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VECTORISE THE ASIAN MC PRICER \n",
    "* compare the outputs and time to completion \n",
    "\n",
    "* Will also need to alter the original BM simulation code slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## slightly alter the BM simulation to simultaneously simulate all the changes at once, to plug into the vectorised MC\n",
    "# Note new input: numsim, the number of paths.\n",
    "\n",
    "\n",
    "def bmsim_vec(T, N, X0=0, mu=0, sigma=1, numsim=1):\n",
    "    \"\"\"Simulate a vectorised \"numsim\" amount of Brownian motion paths.\"\"\"\n",
    "    deltaT = float(T) / N\n",
    "    tvec = np.linspace(0, T, N + 1)\n",
    "    z = np.random.randn(numsim, N + 1)\n",
    "    dX = mu * deltaT + sigma * np.sqrt(deltaT) * z\n",
    "\n",
    "    dX[:, 0] = 0.0\n",
    "    X = np.cumsum(dX, axis=1)\n",
    "\n",
    "    X += X0\n",
    "    return tvec, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note for an explanation on each step, see the asianmc (loop version) above\n",
    "def asian_mc_vec(S0, K, T, r, sigma, q, N, numsim=10000):\n",
    "    \"\"\"Monte Carlo price of an arithmetic average Asian call. Vectorised Version\"\"\"\n",
    "    X0 = np.log(S0)\n",
    "    nu = r - q - 0.5 * sigma**2\n",
    "\n",
    "    # simulate all paths at once with the numsim altered bmsim_vecm above:\n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim)\n",
    "    S = np.exp(X)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1) - K, 0.0)\n",
    "    g = np.exp(-r * T) * payoffs\n",
    "    C = g.mean()\n",
    "    s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq / np.sqrt(numsim) * s\n",
    "    Cu = C + zq / np.sqrt(numsim) * s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define dummy data for testing purposes:\n",
    "S0 = 11\n",
    "K = 10\n",
    "T = 3 / 12.0\n",
    "r = 0.02\n",
    "sigma = 0.3\n",
    "q = 0.01\n",
    "N = 10\n",
    "\n",
    "# ensure random seed for comparability\n",
    "np.random.seed(0)\n",
    "\n",
    "C0_v, Cl_v, Cu_v = asian_mc_vec(S0, K, T, r, sigma, q, N)\n",
    "C0_v, Cl_v, Cu_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"confidence interval band: {}\".format(Cu_v - Cl_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit asian_mc_vec(S0, K, T, r, sigma, q, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check both results are identical\n",
    "np.allclose(C0_v, C0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice a very significant increase in speed in the vectorised version Vs. the loop with the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vr_mc'></a>\n",
    "\n",
    "# VARIANCE REDUCTION TECHNIQUES IN MC PRICING\n",
    "* In standard Monte Carlo, the length of the confidence interval for $\\theta\\equiv\\mathbb{E}[X]$ is proportional to $\\hat{\\sigma}/\\sqrt{n}$, where $\\sigma$ is the standard deviation of $X$.\n",
    "* Thus to increase the accuracy by a factor of 10, we need 100 times as many samples.\n",
    "* Variance reduction techniques aim to improve the accuracy of the estimate, without increasing $n$. (at scale, the computational saving become non-trivial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## METHOD (1):  ANTITHETIC SAMPLING\n",
    "#### RECALL: \n",
    "* The crude MC estimate for $\\theta\\equiv \\mathbb{E} [X]$, based on $n$ independent draws $X_i$, is\n",
    "$$\n",
    "\\hat{\\theta}\\equiv \\frac{1}{n}\\sum_{i=1}^n X_i.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "* Now suppose that we can somehow sample $n$ pairs $(X_i, \\tilde X_i)$, such that\n",
    "  * both $X_i$ and $\\tilde X_i$ are drawn from the distribution of $X$;\n",
    "  * the *pairs* $(X_i, \\tilde X_i)$ are independent across $i$;\n",
    "  * for each $i$, $X_i$ and $\\tilde X_i$ are (negatively) correlated.\n",
    "* The antithetic variable estimator is then\n",
    "$$\n",
    "\\hat{\\theta}_{AV}\\equiv \\frac{1}{2}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i+\\frac{1}{n}\\sum_{i=1}^n \\tilde X_i\\right).\n",
    "$$\n",
    "\n",
    "\n",
    "* Thus, we can re-write the MC estimator as: \n",
    "$$\n",
    "\\hat{\\theta}_{AV}=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{X_i+\\tilde X_i}{2}\\right),\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "* Accordingly, the variance of this new estimator can be calculated as (and from applying some of the traditional rules of covariances)\n",
    "\\begin{align*}\n",
    "\\sigma^2_{AV}&\\equiv \\mathrm{var}\\left[\\frac{X_i+\\tilde X_i}{2}\\right]=\\frac{1}{4}\\left(\\mathrm{var}[X_i]+\\mathrm{var}[\\tilde X_i] +2\\mathrm{cov}[X_i,\\tilde X_i]\\right)\\\\\n",
    "%&=\\frac{1}{2}\\left[\\mathrm{var}[X_i] +\\mathrm{cov}[X_i,\\tilde X_i]\\right)\n",
    "&=\\frac{\\sigma^2}{2}\\big(1+\\rho(X_i,\\tilde X_i)\\big).\n",
    "\\end{align*}\n",
    "\n",
    "* Thus, we observe that efficiency is gained whenever the correlation $\\rho(X_i,\\tilde X_i)$ is negative- as it reduces the value of the expression: $\\frac{\\sigma^2}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmsim_vec_av(T, N, X0=0, mu=0, sigma=1, numsim=1, av=True):\n",
    "    \"\"\"\n",
    "    Simulate \"numsim\" of Brownian motion paths. (Drift (mu) = 0))\n",
    "    If av=True, then 2*numsim paths are returned\n",
    "    - where paths numsim:2*numsim+1 are the antithetic paths.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    deltaT = float(T) / N\n",
    "    tvec = np.linspace(0, T, N + 1)\n",
    "    z = np.random.randn(numsim, N + 1)\n",
    "    if av == True:\n",
    "        z = np.concatenate(\n",
    "            (z, -z)\n",
    "        )  # yields an array of shape (2*numsim,N+1); z stacked on -z\n",
    "    dX = mu * deltaT + sigma * np.sqrt(deltaT) * z\n",
    "    dX[:, 0] = 0.0\n",
    "    X = np.cumsum(dX, axis=1)\n",
    "    X += X0\n",
    "    return tvec, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.G. of the BM sim with antithetic BM paths: there is a symmetrical nature to each path\n",
    "# which represents the negative correlation associated with each path\n",
    "np.random.seed(0)\n",
    "tvec, W = bmsim_vec_av(1, 1000, numsim=3, av=True)\n",
    "W = pd.DataFrame(W.transpose(), index=tvec)\n",
    "W.plot().legend().remove()\n",
    "plt.title(\"Regular and Antithetic Brownian Motion Paths\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$W_t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* just need to make a relatively smaller alteration to the original vec_mc code to account for the now concatenated (z) series of correlated normal distribution draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see original MC method asian_mc_vec for step-by-step code comments\n",
    "def asian_mc_vec_as(S0, K, T, r, sigma, q, N, numsim=10000, ant_sampling=True):\n",
    "    \"\"\"\n",
    "    Monte Carlo price of an arithmetic average Asian call.\n",
    "    Antithetic Sampling default is True; set to false to return regular MC\"\"\"\n",
    "\n",
    "    X0 = np.log(S0)\n",
    "    nu = r - q - 0.5 * sigma**2\n",
    "    _, X = bmsim_vec_av(T, N, X0, nu, sigma, numsim, av=True)\n",
    "    S = np.exp(X)\n",
    "\n",
    "    # apply payoff function for asian call (defined in the asian options introduction section)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1) - K, 0.0)\n",
    "    g = np.exp(-r * T) * payoffs\n",
    "\n",
    "    if ant_sampling == True:\n",
    "        g = 0.5 * (g[:numsim] + g[numsim:])\n",
    "\n",
    "    C = g.mean()\n",
    "    s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq / np.sqrt(numsim) * s\n",
    "    Cu = C + zq / np.sqrt(numsim) * s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# pass in dummy data\n",
    "S0 = 11\n",
    "K = 10\n",
    "T = 3 / 12.0\n",
    "r = 0.02\n",
    "sigma = 0.3\n",
    "q = 0.01\n",
    "N = 10\n",
    "numsim = 10000\n",
    "\n",
    "# run the mc pricer with ant_sampling\n",
    "C_as, Cl_as, Cu_as = asian_mc_vec_as(\n",
    "    S0, K, T, r, sigma, q, N, numsim, ant_sampling=True\n",
    ")\n",
    "\n",
    "# return value and the confidence interval\n",
    "C_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"confidence interval band asian MC with AS: {}\".format(Cu_as - Cl_as))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The confidence interval band has shrunk from 0.035 in the regular asian_mc_vec to 0.008 for the antithetic sampling version; which represents a solid improvement in variance reduction "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py 3.12.5 (MktNotesGen)",
   "language": "python",
   "name": "uvpy3125_mktnotesgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
